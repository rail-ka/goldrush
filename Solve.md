# Решение

1. Получаем площади с сундуками, допустим оптимальным будет поиск 35х35.
2. Если на заданном поле есть сундуки - отправляем в обработку поле.
3. В самом начале лицензий нет поэтому за время обработки карты мы еще получаем бесплатные лицензии. Сколько успеем, потом будет покупать платные лиценции.
4. Когда поле попадает в обработку, нужно узнать есть ли у нас лицензии. Если есть - копаем, если нет - покупаем или берем бесплатные если нет денег.
5. Какую сумму указывать за лицензию?
6. Берем лицензию и смотрим осталось ли у нее разрешения на копку. Если нет - берем новую лицензию. Если есть - начинаем копать.
7. Нужно ли еще раз проверять площадь на наличие сундуков? Наверное да, смотреть на вероятность одного клада в обрабатываемом поле. Если вероятность слишком маленькая, то еще раз проверять поле на наличие сунуков с уменьшенной площадью. Нужно ли проверять одну точку?
8. Копать. Если в данной точке есть сундуки - копать, пока не найдем то количество сундуков, которое определено на площади. Можно ли копать одновременно в нескольких точках на площади? Если нашли все сундуки - остановить копание во всех точках. Если дошли до -10 этажа - в данной точке копать прекращаем.
9. Меняем сундуки на деньги. Когда меняем? Сразу или потом?
10. Когда делаются по очереди Explore много раз, сервер захлебывается, нужно видимо давать интервал другими запросами? Хотя среднее значение только в 2 раза больше минимального, значит нужно сбрасывать долгие подключения (более 3-5мс?)

10 минут = 60 * 10 = 600 секунд = 600_000 миллисекунд

1/2 area
cpus: 1 size_x: 50
end: 376_157
areas_count: 122_500 areas_without_gold: 16_121, profit: 7,4 (14%)
explore min: 1632 max: 23_707 avg: 3069
amounts min: 1 max: 11 avg: 2
error_code: 1000, count: 2214
error_code: 1002, count: 94

1/2 area (1/4 for every cpu)
cpus: 2, for every:
size_x: 35 end: 447_164
areas_count: 87_500 areas_without_gold: 20_874, profit: 4 (24%)
explore min: 1516 max: 23_019 avg: 5109
error_code: 1000, count: 2489
error_code: 1002, count: 33

1/20 area
size_x: 35 size_y: 1 cpus: 1 area_divisor: 20
end: 50_972
areas_count: 17_500 areas_without_gold: 4314, profit: 4 (24%)
explore min: 1395 max: 32_649 avg: 2911
amounts min: 1 max: 8 avg: 1 extremes_count: 54
item: 1 count: 6043
item: 2 count: 4193
item: 3 count: 1911
item: 4 count: 665
item: 5 count: 202
item: 6 count: 43
item: 7 count: 9
item: 8 count: 2
error_code: 1000, count: 110
error_code: 1002, count: 8
Metric { min: 1, max: 8, sum: 24_169, count: 13_068 }

// при step = 5 areas_without_gold варьируется от 1 до 2х
// небходимо будет проверить 30 точек

cpu: 0 step_x: 5 step_y: 1 cpus: 1 area_divisor: 1
size_x: 35 size_y: 1
end: 12
areas_without_gold: 1
explore min: 1317 max: 2522 avg: 1696
area_amounts_min: 1 area_max: 2
amount_in_area: 1 areas_count: 4
amount_in_area: 2 areas_count: 2

// при step = 5 areas_without_gold варьируется от 1 до 2х
// небходимо будет проверить 28 точек

cpu: 0 step_x: 7 step_y: 1 cpus: 1 area_divisor: 1
size_x: 35 size_y: 1
end: 13
areas_without_gold: 1
explore min: 1984 max: 4744 avg: 2650
area_amounts_min: 1 area_max: 3
amount_in_area: 1 areas_count: 2
amount_in_area: 3 areas_count: 2

cpu: 0 step_x: 1 step_y: 1 cpus: 1 area_divisor: 1
size_x: 7 size_y: 1 areas_count: 7 
end: 12
explore min: 1620 max: 1948 avg: 1798
exists in point: 3

логи 15k или 150 строк

у меня в графане почему то появился третий дашборд?

чтобы просто догнать участников на обмен монет нужно 200 секунд, что является 1/3 от общего времени:
47 монет в сундуке максимум, 900к монет - это примерно 19к сундуков, на один сундук 10мс = 190 секунд.

исследовать можно не все поле, так как времени все равно не хватит. Поэтому исследуем например 1/3 поля пока, увеличивая size_x.
если брать 1/20 поля, то теоретически можно получить 1млн монет.
если 1/10 - то 2млн...
для 5.7млн монет нужно исследовать 1/4 поля.

разделять на cpu похоже не имеет смысла, так как время все равно увеличивается вдвое... и ошибок больше и среднее время запроса увеличивается...

возможно нужна приоритетная очередь для обработки участков с бОльшим количеством сундуков первыми...
есть залежи сундуков...

вообще нужно сделать бинарный поиск: делим карту на 7 площадей, смотрим где больше сундуков, выбираем площадь, далее делим еще на некоторую часть, снова смотрим где больше и т.д...
на 7 делить смысла нет, все одинаковые

Про блокировки и синхронизацию данных - по сути мы можем не аллоцировать и деаллоцировать данные, мы можем использовать arena с фиксированным количеством памяти для этого. Но поможет ли это? У нас по сути все упирается во время выполения запросов (время ответа сервера)


А если поймана ошибка при explore - {“code”:503,”message”:”service unavailable”} - значит ли что сервер уже отрубился и не будет больше принимать запросы ?
Скорее всего больше 1000 rps пытался выжать из сервера.

Вот ещё не понятно где остальное улучшать, лицензии держатся >4, кандидаты на выкопку держу 400 штук, под конец оставляю чуть чуть, клады сразу продаю

А в чем проблема с кэшем? Там просто тупо нет конкарренси? Посылаешь два запроса одновременно, оба обрабатываются в два разв дольше, или что?

key: HOSTNAME value: 0b4bb8db3045
key: ADDRESS value: a461d5dec877
key: CODERUNNER_UID value: 992
key: CODERUNNER_GID value: 988

можно попробовать поиграть в сапера-наоборот. устанавливать вес для площадей. если на площади найдены сундуки, то с некой вероятностью рядом будет меньше сундуков. и сначала исследовать площади с бОльшим весом. Площади будут иметь признак обработан-нет. Как хранить сетку 3500х3500? Обычным вложенным массивом?

использовать атомарные типы по возможности.

я ищу в 2 потока (OS threads) explore по 35 точек.
обработал некую часть поля, нашел там поля по 35х35 с приоритетом. Отправляю на обработку другому воркеру? но так нельзя потому что за этот метод должны отвечать только 2 треда.

есть другой воркер. у него тоже 2 потока. может каждый поток воркера будет отправлять своему потоку своего воркера? можно попробовать. тек же перед этим нужно делать запросы лицензий.

мы должнв иметь структуру лицензий с методоами запроса новых лицензий межпотоковым доступом. либо делим лицензии на 2. у каждого потока будет своя структура со своими 5 лицензиями. лицензии должны пополняться сами пока идет работа?

у нас одновременная работа:
- explore
- pull license
- dig
- cash

когда находим dig - можно отправлять в mpsc канал для обработки клада. возможно кошелек поделить не получится и нужно будет обернуть в arc<mutex>. лицензии тоже не получится поделить. нужны межпотоковые структуры данных.

для лицензий нам не нужен BinaryHeap, но мы можем для каждого потока брать свою лицензию? что если использовать очередь для лицензий?
